# Environment Configuration

# ============================================
# LLM Provider Configuration (PRIVACY SWITCH)
# ============================================

# Provider: "openai" | "ollama" | "lmstudio"
LLM_PROVIDER=openai

# --- OpenAI Configuration ---
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o
# OPENAI_BASE_URL=https://api.openai.com/v1  # Default

# --- Ollama Configuration (Local/Private) ---
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:32b
# OLLAMA_MODEL=llama3.1:70b
# OLLAMA_MODEL=deepseek-r1:32b

# --- LMStudio Configuration (Future/Local) ---
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LMSTUDIO_MODEL=local-model-name

# ============================================
# LangSmith (Optional - for tracing)
# ============================================
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your-langsmith-api-key
# LANGCHAIN_PROJECT=bpmn-generator

# ============================================
# Database (LangGraph Checkpoints)
# ============================================
DATABASE_URL=sqlite:///checkpoints.db
# DATABASE_URL=postgresql://user:pass@localhost/bpmn_generator  # Production

# ============================================
# Logging
# ============================================
LOG_LEVEL=INFO
# LOG_LEVEL=DEBUG  # For development

# ============================================
# Generation Settings
# ============================================
MAX_REVISION_COUNT=3
CONTEXT_WINDOW_SIZE=10
TEMPERATURE=0.1  # Low for deterministic outputs

# ============================================
# RAG (Future - Optional)
# ============================================
# VECTOR_STORE_PATH=./vector_store
# EMBEDDING_MODEL=text-embedding-3-small
